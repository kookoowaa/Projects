# NLP and clustering with review data
>- Transfer 러닝 고려 (네이버 리뷰? IRW 리뷰?)


## General understanding of text analysis
- 텍스트 마이닝 기법을 이용한 경제심리 관련 문서 분류(서울대학교/한국은행, 2017): https://wikidocs.net/book/2155 (**deprecated**)
- 한국어 임베딩(2019.09): https://ratsgo.github.io/natural%20language%20processing/2019/09/12/embedding/
- 한국어 임베딩 튜토리얼페이지: https://ratsgo.github.io/embedding/
- 딥 러닝을 이용한 자연어 처리 입문 (2020.02): https://wikidocs.net/book/2155

## Word2Vec
- Word2Vec으로 문장 분류하기 (2017.03): https://ratsgo.github.io/natural%20language%20processing/2017/03/08/word2vec/
- word2vec, Bidirectional RNN, GRU, 임베딩 시각화 (2018.06): https://excelsior-cjh.tistory.com/156?category=940399

## BERT
- BERT에 대해 쉽게 알아보기1 - BERT는 무엇인가, 동작구조 (2020.02): https://ebbnflow.tistory.com/151
- BERT 세미나용 - 초등학생도 이해할 수 있는 수준으로 (2019.09): https://sayhellotoai.blogspot.com/2019/09/bert.html
- ELMo, Transformer, BERT에 대한 간략 정리(2019.11): http://blog.naver.com/PostView.nhn?blogId=wpdls6012&logNo=221721511272
- 딥러닝으로 동네생활 게시글 필터링하기 (당근마켓, 2019.05): https://medium.com/daangn/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9C%BC%EB%A1%9C-%EB%8F%99%EB%84%A4%EC%83%9D%ED%99%9C-%EA%B2%8C%EC%8B%9C%EA%B8%80-%ED%95%84%ED%84%B0%EB%A7%81%ED%95%98%EA%B8%B0-263cfe4bc58d
- 인공지능(AI) 언어모델 ‘BERT(버트)'는 무엇인가 (2019.01): http://www.aitimes.kr/news/articleView.html?idxno=13117
- BERT 논문정리(2018.12): https://mino-park7.github.io/nlp/2018/12/12/bert-%EB%85%BC%EB%AC%B8%EC%A0%95%EB%A6%AC/?fbclid=IwAR3S-8iLWEVG6FGUVxoYdwQyA-zG0GpOUzVEsFBd0ARFg4eFXqCyGLznu7w
- BERT 톺아모기 (2018.12): http://docs.likejazz.com/bert/
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2019.08): https://soobarkbar.tistory.com/47
- Recent Trends in Deep Learning Based Natural Language Processing (2019.12): http://blog.naver.com/PostView.nhn?blogId=kryj9625&logNo=221745319803
- **BERT 2.0(TensorFlow) 사용 가이드 (google): https://cloud.google.com/tpu/docs/tutorials/bert-2.x?hl=ko**
- **구글 Colab을 이용한 BERT-Base Model 학습하기 (2019.04): https://blog.nerdfactory.ai/2019/04/25/learn-bert-with-colab.html**
- **BERT-Multilingual model을 이용해 KorQuAD 수행 해보기 http://mlgalaxy.blogspot.com/2019/01/bert-multilingual-model-korquad-part-1.html**
- Simple BERT using TensorFlow 2.0 (2019.08): https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22
- Korean BERT pre-trained cased (2020.02): https://github.com/SKTBrain/KoBERT- 
