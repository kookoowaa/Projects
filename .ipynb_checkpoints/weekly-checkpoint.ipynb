{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주간 매출동양 자료 정제 자동화 (MY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author.............: Park, Pablo Chanwoo\n",
    "# File name..........: weekly.py\n",
    "# Written Date.......: 2018-12-28\n",
    "# Program Description: program automation for crawling and processing weekly report data for Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  ## 크롬드라이버\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re  ## 매장수 정제\n",
    "import time  ## 정지 및 시간 확인\n",
    "import datetime  ##날자 적어서 파일명 확인\n",
    "import os  ## 메뉴파일 있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define chromedriver\n",
    "driver = webdriver.Chrome(\"d:/git/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define stores to crawl data from\n",
    "stores = [\"arcoris\", \"ipc\", \"setia-city\", \"mytown\", \"genting\", \"pearl\", \"penang\", \"sunway-pyramid\", \"pavilion\", \"1-utama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date from(dd): 11\n",
      "month from(mm): 12\n",
      "year from(yyyy): 2018\n",
      "date to(dd): 17\n",
      "month to(mm): 12\n",
      "year to(yyyy): 2018\n"
     ]
    }
   ],
   "source": [
    "#### Define date variables\n",
    "date_from= []\n",
    "date_from.append(input('date from(dd): '))\n",
    "date_from.append(input('month from(mm): '))\n",
    "date_from.append(input('year from(yyyy): '))\n",
    "range_from = date_from[0]+'%2F'+date_from[1]+'%2F'+date_from[2]+'+00%3A00%3A27'\n",
    "\n",
    "date_to= []\n",
    "date_to.append(input('date to(dd): '))\n",
    "date_to.append(input('month to(mm): '))\n",
    "date_to.append(input('year to(yyyy): '))\n",
    "range_to = date_to[0]+'%2F'+date_to[1]+'%2F'+date_to[2]+'+00%3A00%3A27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define html links to crawl data from\n",
    "sales_summary = 'https://kyochon.revelup.com/brand/reports/sales_summary/json/?dining_option=&employee=&online_app=&online_app_type=&online_app_platform=&show_unpaid=1&show_irregular=1&range_from={}&range_to={}&format=csv'.format(range_from, range_to)\n",
    "hourly_sales = 'https://kyochon.revelup.com/reports/hourly_sales/export/csv/?aggregate_format=hours&employee=&online_app=&online_app_type=&online_app_platform=&dining_option=&show_unpaid=1&show_irregular=1&no-filter=0&day_of_week=&range_from={}&range_to={}'.format(range_from, range_to)\n",
    "product_mix = 'https://kyochon.revelup.com/reports/product_mix/data/?sort_by=&sort_reverse=&combo_expand=&employee=&online_app=&online_app_type=&online_app_platform=&dining_option=&show_unpaid=1&show_irregular=1&sort_view=1&show_class=1&quantity_settings=0&no-filter=0&day_of_week=&range_from={}&range_to={}&format=csv'.format(range_from, range_to)\n",
    "#### NOTE that the report can be downloaded via URL API, per store you are logged onto (28 Dec. 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your user name please (to access download folder): pablo\n",
      "Initiating program...\n"
     ]
    }
   ],
   "source": [
    "#### Define directory\n",
    "user_name = input(\"Enter your user name please (to access download folder): \")\n",
    "directory = 'D:/Users/{}/Downloads/'.format(user_name)  ## adjustment maybe needed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating program...\n"
     ]
    }
   ],
   "source": [
    "beginning = time.time()\n",
    "print(\"Initiating program...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function to sort sales by menu\n",
    "def pd_mix_func(file):\n",
    "    global tmp_pd, sales_by_menu\n",
    "    \n",
    "    try:\n",
    "        tmp_pd = pd.merge(pd.read_csv(directory+file, engine='python').groupby(\"Class\", as_index=False).sum(),\n",
    "                   menu,\n",
    "                   left_on=\"Class\",\n",
    "                   right_on = \"asis\").groupby('tobe').sum()['Total Sales']\n",
    "    except:\n",
    "        for i in range(len(tmp_pd)):\n",
    "            tmp_pd[i] = np.NaN\n",
    "    if store == stores[0]:\n",
    "        sales_by_menu = pd.DataFrame(tmp_pd)\n",
    "    else:\n",
    "        sales_by_menu = pd.concat([sales_by_menu, pd.DataFrame(tmp_pd)], axis = 1, sort = False)\n",
    "    sales_by_menu = sales_by_menu.drop(\"Delete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function to sort sales by time\n",
    "def hourly_func(file):\n",
    "    global sales_by_time\n",
    "    \n",
    "    temp = pd.read_csv(directory+file, engine='python')[['Time', 'Sales']].iloc[9:24]\n",
    "    \n",
    "    if store == stores[0]:\n",
    "        sales_by_time = pd.DataFrame(temp)\n",
    "    else:\n",
    "        sales_by_time = pd.concat([sales_by_time, pd.DataFrame(temp)[\"Sales\"]], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function to sort sales by day, and sales by order type\n",
    "def sales_func(file):\n",
    "    global daily_gross_sales, daily_net_sales, sales_by_order\n",
    "    \n",
    "    \n",
    "    temp = pd.read_csv(directory+file, engine='python')#[['Gross Sales', 'Net Sales','Togo Sales', 'Eatin Sales', 'Delivery Sales',\n",
    "                                                       # 'Catering Sales', 'WebOrder', 'Online Sales', 'Shipping Sales', 'Takeaway']]\n",
    "    temp1 = pd.DataFrame([temp[['Eatin Sales', 'Catering Sales']].sum().sum(),\n",
    "                         temp[['Togo Sales', 'Takeaway']].sum().sum() ,\n",
    "                         temp[['Delivery Sales', 'Online Sales', 'Shipping Sales']].sum().sum()],\n",
    "                        index = ['Dining', 'Take-out', 'Delivery'])\n",
    "    \n",
    "    if store == stores[0]:\n",
    "        daily_gross_sales = pd.DataFrame(temp['Gross Sales'])\n",
    "        daily_net_sales = pd.DataFrame(temp['Net Sales'])\n",
    "        sales_by_order = temp1\n",
    "    else:\n",
    "        daily_gross_sales = pd.concat([daily_gross_sales,temp['Gross Sales']], axis = 1, sort = False)\n",
    "        daily_net_sales = pd.concat([daily_net_sales,temp['Net Sales']], axis = 1, sort = False)\n",
    "        sales_by_order = pd.concat([sales_by_order, temp1], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹사이트 접속 및 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Open the web-site\n",
    "driver.get(\"https://kyochon.revelup.com/login/?next=/dashboard/\") # POS web-site\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Log-in\n",
    "driver.find_element_by_xpath('//*[@id=\"id_username\"]').send_keys(\"JayceKim\")\n",
    "driver.find_element_by_xpath('//*[@id=\"id_password\"]').send_keys(\"Qwer1234!!\")\n",
    "driver.find_element_by_xpath('//*[@id=\"form-login\"]/fieldset/div[3]/input').click()\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Open store lists\n",
    "driver.find_element_by_xpath('//*[@id=\"header\"]/div[2]/div[2]/div[2]').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Retrieve total number of stores\n",
    "tmp = driver.find_element_by_class_name('fancytree-title').text\n",
    "n_store = int(re.findall(string=tmp, pattern = '[0-9]+')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data fetching on store #1...\n",
      "data fetching on store #2...\n",
      "data fetching on store #3...\n",
      "data fetching on store #4...\n",
      "data fetching on store #5...\n",
      "data fetching on store #6...\n",
      "data fetching on store #7...\n",
      "data fetching on store #8...\n",
      "data fetching on store #9...\n",
      "data fetching on store #10...\n",
      "data fetching on store #11...\n"
     ]
    }
   ],
   "source": [
    "#### Fetch data from the web-site \n",
    "for i in range(1, n_store+1):\n",
    "    print('data fetching on store #{}...'.format(str(i)))\n",
    "    #### Access Store\n",
    "    if i > 1:\n",
    "        driver.find_element_by_xpath('//*[@id=\"header\"]/div[2]/div[2]/div[2]').click()\n",
    "        time.sleep(5)\n",
    "    driver.find_element_by_xpath('//*[@id=\"establishments-tree\"]/div/div[3]/ul/li[1]/ul/li[{}]/span[2]/span[3]'.format(i)).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #### Run URL APIs\n",
    "    driver.get(sales_summary)\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.get(hourly_sales)\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.get(product_mix)\n",
    "    driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수집한 데이터 정제 (메뉴 카테고리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read fetched data\n",
    "for i in stores:\n",
    "\t#### Read files\n",
    "    product_mix = \"Product_Mix_{}_{}_00-00_{}_00-00.csv\".format(i,\n",
    "                                                            (date_from[2] + '-' +date_from[1] +'-'+ date_from[0]),\n",
    "                                                            (date_to[2] + '-' +date_to[1] +'-'+ date_to[0]))\n",
    "    #### Group by classes\n",
    "    if i =='arcoris':\n",
    "        tmp = pd.read_csv(directory+product_mix).groupby('Class', as_index = False).sum()\n",
    "    else:\n",
    "    \t#### In case file is empty, pass the file\n",
    "        try:\n",
    "            tmp = pd.concat([tmp, pd.read_csv(directory+product_mix).groupby('Class', as_index = False).sum()])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Retrieve unique menus\n",
    "tmp = tmp.Class.unique()\n",
    "tmp.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Re-group categories for report (\"Beverage\", \"Chicken\", \"Side\", \"Salad\", \"A-La-Carte\")\n",
    "#### If previous classification is avaiable, read\n",
    "if pd.Series(os.listdir('weekly/')).isin([\"menu.csv\"]).sum() == 1:\n",
    "\tmenu = pd.read_csv('weekly/menu.csv')\n",
    "#### If not, make classification.\n",
    "#### The below \"tobe\" may need rearrangement\n",
    "else:\n",
    "\ttobe = [\"A-La-Carte\", \"Beverage\", \"Beverage\", \"Beverage\", \"Chicken\",\n",
    "\t\t\t\"Delete\", \"Delete\", \"Chicken\", \"Beverage\", \"Chicken\",\n",
    " \t\t\t\"Beverage\", \"Chicken\", \"Beverage\", \"Side\", \"Chicken\", \n",
    " \t\t\t\"Chicken\", \"Salad\", \"Delete\", \"Side\", \"Beverge\"]\n",
    "\tmenu = pd.DataFrame([tmp, tobe]).T\n",
    "\tmenu.columns = ['asis', 'tobe']\n",
    "\t#### final menu to be saved as csv\n",
    "\tmenu.to_csv(\"weekly/menu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수집된 데이터 리포트로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read process data per report\n",
    "for store in stores:\n",
    "\t#### call reports per store and run user-defined-function\n",
    "    product_mix = \"Product_Mix_{}_{}_00-00_{}_00-00.csv\".format(store,\n",
    "                                                            (date_from[2] + '-' +date_from[1] +'-'+ date_from[0]),\n",
    "                                                            (date_to[2] + '-' +date_to[1] +'-'+ date_to[0]))\n",
    "    hourly_sales = \"Hourly_Sales_{}_{}_00-00_{}_00-00.csv\".format(store,\n",
    "                                                            (date_from[2] + '-' +date_from[1] +'-'+ date_from[0]),\n",
    "                                                            (date_to[2] + '-' +date_to[1] +'-'+ date_to[0]))\n",
    "    sales_summary = \"Sales_Summary_{}_{}_00-00_{}_00-00.csv\".format(store,\n",
    "                                                            (date_from[2] + '-' +date_from[1] +'-'+ date_from[0]),\n",
    "                                                            (date_to[2] + '-' +date_to[1] +'-'+ date_to[0]))\n",
    "    pd_mix_func(product_mix)\n",
    "    hourly_func(hourly_sales)\n",
    "    sales_func(sales_summary)\n",
    "    \n",
    "    #### at last store, assign column names to each report DataFrame\n",
    "    if store == stores[-1]:\n",
    "        sales_by_time.columns = ['Time'] + stores\n",
    "        sales_by_menu.columns = stores\n",
    "        daily_gross_sales.columns = stores\n",
    "        daily_net_sales.columns = stores\n",
    "        sales_by_order.columns = stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엑셀로 전송"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Weekly/weekly_report({}{}-{}{}).xlsx'.format(date_from[1], date_from[0], date_to[1], date_to[0]), engine='xlsxwriter')\n",
    "\n",
    "daily_net_sales.to_excel(writer, sheet_name=\"raw data\")\n",
    "daily_gross_sales.to_excel(writer, sheet_name=\"raw data\", startrow=9)\n",
    "sales_by_order.to_excel(writer, sheet_name=\"raw data\", startrow=9+9)\n",
    "sales_by_menu.to_excel(writer, sheet_name=\"raw data\", startrow=9+9+5)\n",
    "sales_by_time.to_excel(writer, sheet_name=\"raw data\", startrow=9+9+5+9, index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로그램 수행 시간 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total process finished at 5min, 44second\n"
     ]
    }
   ],
   "source": [
    "elap_min, elap_sec = np.divmod(time.time()-beginning, 60)\n",
    "print(\"Total process finished at {}min, {}second\". format(int(elap_min), int(elap_sec)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
